# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1482JvOtXX1JIMEI6w8Fdvfp3V7t97-iY
"""


import mediapipe as mp
import cv2
import numpy as np

class Pr():
    
    # init method or constructor
    def __init__(self,image):
        self.image = image
       
    def get_bounding_box(hand_landmarks, image, margin=0.2):
        # Initialize minimum and maximum values for x and y coordinates
        x_min = y_min = 1.0
        x_max = y_max = 0.0

        # Loop through each landmark of the hand
        for landmark in hand_landmarks.landmark:
            # Get the x, y, and z coordinates of the landmark
            x, y, z = landmark.x, landmark.y, landmark.z
            # Update the minimum and maximum values for x and y coordinates
            x_min = min(x_min, x)
            y_min = min(y_min, y)
            x_max = max(x_max, x)
            y_max = max(y_max, y)
            
        # Calculate the width and height of the bounding box
        width, height = x_max - x_min, y_max - y_min
        # Apply the margin to the bounding box coordinates
        x_min -= width * margin
        y_min -= height * margin
        x_max += width * margin
        y_max += height * margin

        # Convert the bounding box coordinates to integer values
        x_min, y_min = int(x_min * image.shape[1]), int(y_min * image.shape[0])
        x_max, y_max = int(x_max * image.shape[1]), int(y_max * image.shape[0])

        # Return the bounding box coordinates
        return x_min, y_min, x_max, y_max


    
    @staticmethod
    def detect_crop_and_segment_hands(image):
        two_hands_detected = False
        # Initialize MediaPipe Hands
        mp_drawing = mp.solutions.drawing_utils
        mp_hands = mp.solutions.hands
        hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.05)

        # Convert the frame to RGB format
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # Run the hand detection model on the frame
        results = hands.process(image)
        # If no hands were detected, return the original frame
        if results.multi_hand_landmarks is None:
            hands.close()
            return False,None

        # Initialize a list to store the cropped images for both hands
        cropped_images = []

        # Loop through each detected hand
        for hand_landmarks in results.multi_hand_landmarks:
                
            # Get the bounding box coordinates for the hand
            x_min, y_min, x_max, y_max = Pr.get_bounding_box(hand_landmarks, image)

            # Adjust bounding box coordinates to ensure crop falls within frame bounds
            x_min = max(0, x_min)
            y_min = max(0, y_min)
            x_max = min(image.shape[1], x_max)
            y_max = min(image.shape[0], y_max)
            
            
            # Apply hand segmentation mask
            mask_image = np.zeros_like(image)
            mp_drawing.draw_landmarks(mask_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)
            mask_image = cv2.cvtColor(mask_image, cv2.COLOR_RGB2GRAY)
            _, mask_image = cv2.threshold(mask_image, 1, 255, cv2.THRESH_BINARY)
            
            mask_image_rgb = np.repeat(mask_image[..., np.newaxis], 3, axis=2)
            #mask_image = cv2.resize(mask_image, (128,128))
            cropped_images.append(mask_image_rgb)
           
        # Clean up
        hands.close()
        if len(cropped_images) ==2:
            two_hands_detected = True
            cropped_images[0] = np.maximum(cropped_images[0], cropped_images[1])
        
        return two_hands_detected,cropped_images[0]

